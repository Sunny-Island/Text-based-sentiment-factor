{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import threading\n",
    "\n",
    "# 设置请求头\n",
    "head = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures_code = []\n",
    "\n",
    "def decode(url):\n",
    "    req = urllib.request.Request(url,headers=head)\n",
    "    r = urllib.request.urlopen(req).read()\n",
    "    soup = BeautifulSoup(r.decode('utf-8'))\n",
    "    return soup\n",
    "\n",
    "def re_findall(context, list_):\n",
    "    a = re.findall(context,html.body.find_all(\"script\")[5].get_text().strip('\\r').strip('\\n'))\n",
    "    for i in a:\n",
    "        list_.append(i.split(\":\")[1])\n",
    "        \n",
    "def parse(html):\n",
    "    #主帖相关\n",
    "    if html.body.find_all(\"div\", class_=\"zwcontentmain xeditor\") == []: pass\n",
    "    else: \n",
    "        reviews.append(html.body.find_all(\"div\", class_=\"zwcontentmain xeditor\")[0].get_text()) #主帖内容\n",
    "        check_time.append(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))) #查询时间\n",
    "        for i in html.body.find_all('div',{'id':'zwcontt'}): #主贴发帖人信息\n",
    "            for item in i.find_all('div',class_= 'data'):\n",
    "                user_id.append(json.loads(item.attrs['data-json'])[\"user_id\"])\n",
    "                user_nickname.append(json.loads(item.attrs['data-json'])[\"user_nickname\"])\n",
    "                user_age.append(json.loads(item.attrs['data-json'])[\"user_age\"])\n",
    "                influence_power.append(json.loads(item.attrs['data-json'])[\"user_influ_level\"])\n",
    "        user_link = []\n",
    "        for i in html.body.find_all('div',{\"id\":\"zwconttb\"}): #主帖发帖人链接\n",
    "            for item in i.find_all('strong'):\n",
    "                user_link.append(item.find('a').attrs['href'])\n",
    "        for i in html.body.find_all('script')[2]: #主帖所在股吧\n",
    "            stockbar_name=re.findall('stockname = \"\\w+\"',i)[0].split()[-1]\n",
    "        #有无图片\n",
    "        if re.findall(\"img\", str(html.body.find_all(\"div\", class_ = \"zwcontentmain xeditor\"))) != []:\n",
    "            has_picture.append(1)\n",
    "        else: has_picture.append(0)\n",
    "        #发帖时间\n",
    "        for i in html.body.find_all('div',{\"id\":\"zwcontt\"}):\n",
    "            for item in i.find_all('div',class_=\"zwfbtime\"):\n",
    "                publish_time.append(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',item.get_text())[0])\n",
    "        for i in html.body.find_all('div',{\"id\":\"zwlist\"}):\n",
    "            for item in i.find_all('div',class_=\"zwlitime\"):\n",
    "                publish_time.append(re.findall(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}',item.get_text())[0])\n",
    "        #主帖阅读、点赞、评论量\n",
    "        re_findall('\"post_like_count\":\\d+',like_count)\n",
    "        re_findall('\"post_click_count\":\\d+',post_click_count)\n",
    "        if html.body.find_all('div', {\"id\":\"zwcontab\"}) != []:\n",
    "            for item in html.body.find_all('div', {\"id\":\"zwcontab\"}):\n",
    "                a = item.find_all('span', class_=\"comment_num\")[0].get_text()\n",
    "                post_comment_count.append(int(re.findall(r'\\d+',a)[0]))\n",
    "        else: post_comment_count.append(0)\n",
    "        #热评数量，用于去除热评与全评中的重复项\n",
    "        num_hot_comments = 0\n",
    "        for item in html.body.find_all('div',{\"id\":\"zwcontab_hot\"}):\n",
    "            a = item.find_all('span',class_='comment_num')[0].get_text()\n",
    "            num_hot_comments = int(re.findall(r'\\d+',a)[0])\n",
    "        reply_is_author.append(\"true\") #是否为主帖\n",
    "\n",
    "        #评论区内容\n",
    "        #因为热门评论与全部评论重复，所以只选取全部评论爬取\n",
    "        for i in html.body.find_all('div',{\"id\":\"zwlist\"}):\n",
    "            if i.get_text()=='\\n':pass\n",
    "            else:\n",
    "                for item in i.find_all('span',class_=\"zwnick\"): #子帖发帖人链接\n",
    "                    user_link.append(item.find('a').attrs['href'])\n",
    "                for item in (i.find_all('div',{\"class\":\"zwlitext stockcodec\"})): #评论内容和图片\n",
    "                    if not item.find(\"img\"):\n",
    "                        has_picture.append(0)\n",
    "                        if item.get_text().strip('\\n') != '': reviews.append(item.get_text().strip('\\n'))\n",
    "                        else: reviews.append('nan')\n",
    "                    else:\n",
    "                        has_picture.append(1)\n",
    "                        if item.get_text().strip('\\n') != '': reviews.append(item.get_text().strip('\\n'))\n",
    "                        else: reviews.append('nan')\n",
    "\n",
    "                for item in i.find_all('div',class_= 'data'):\n",
    "                    user_id.append(json.loads(item.attrs['data-json'])[\"user_id\"])\n",
    "                    user_nickname.append(json.loads(item.attrs['data-json'])[\"user_nickname\"])\n",
    "                    user_age.append(json.loads(item.attrs['data-json'])[\"user_age\"])\n",
    "                    influence_power.append(json.loads(item.attrs['data-json'])[\"user_influ_level\"])\n",
    "\n",
    "                    check_time.append(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))) #查询时间\n",
    "                    #子帖阅读及评论量置nan\n",
    "                    post_comment_count.append('nan')\n",
    "                    post_click_count.append('nan')\n",
    "            #子帖点赞量    \n",
    "            tmp1 = re.findall('\"reply_like_count\":\\d+',html.body.find_all('script')[5].get_text())[num_hot_comments:]\n",
    "            for i in tmp1:\n",
    "                like_count.append(i.split(\":\")[1])\n",
    "            tmp2 = re.findall('\"reply_is_author\":\\w+',html.body.find_all('script')[5].get_text())[num_hot_comments:]\n",
    "            for i in tmp2:\n",
    "                reply_is_author.append(i.split(\":\")[1])\n",
    "            for i in range(len(user_link)-1):\n",
    "                stockbar_names.append(stockbar_name)\n",
    "\n",
    "        #发帖人相关            \n",
    "        for suburl in user_link:\n",
    "            html = decode(suburl)\n",
    "\n",
    "            for item in html.body.find_all(\"div\", class_ = \"others_fans\"):\n",
    "                followers.append(item.find_all(\"span\")[0].get_text())\n",
    "                fans.append(item.find_all(\"span\")[1].get_text())\n",
    "            for item in html.body.find_all(\"div\", class_ = \"others_info\"):\n",
    "                total_visits.append(item.find_all(\"span\")[0].get_text())\n",
    "                today_visits.append(item.find_all(\"span\")[1].get_text())\n",
    "            if len(re.findall('\\d+',str(html.body.find_all(\"div\", class_=\"level2\")[4])))==1:published_articles.append(0)\n",
    "            else:published_articles.append(re.findall('\\d+',str(html.body.find_all(\"div\", class_=\"level2\")[4]))[1])\n",
    "            if len(re.findall('\\d+',str(html.body.find_all('div', class_=\"level2\")[5])))==1:published_comments.append(0)\n",
    "            else:published_comments.append(re.findall('\\d+',str(html.body.find_all('div', class_=\"level2\")[5]))[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_html = decode('http://guba.eastmoney.com/remenba.aspx?type=2')\n",
    "for i in future_html.find_all('div', class_='allzhutilistb'):\n",
    "    for item in i.find_all('a'):\n",
    "        futures_code.append(item.attrs['href'][:-5])\n",
    "print(futures_code)\n",
    "\n",
    "links = []\n",
    "check_time = []\n",
    "stockbar_names = []\n",
    "user_id = []\n",
    "user_nickname = []\n",
    "reviews = []\n",
    "publish_time = []\n",
    "reply_is_author = []\n",
    "has_picture = []\n",
    "post_click_count = []\n",
    "post_comment_count = []\n",
    "like_count = []\n",
    "published_articles = []\n",
    "published_comments = []\n",
    "followers = []\n",
    "fans = []\n",
    "influence_power = []\n",
    "user_age = []\n",
    "total_visits = []\n",
    "today_visits = []\n",
    "\n",
    "columns = [check_time,stockbar_names,user_id,user_nickname,reviews,publish_time,reply_is_author,has_picture,\n",
    "           post_click_count,post_comment_count,like_count,published_articles,published_comments,\n",
    "           followers,fans,influence_power,user_age,total_visits,today_visits] \n",
    "col_name = ['查询时间','发帖吧','发帖id','发帖人','发帖内容','发帖时间','是否为主贴','是否有图片','阅读量','评论量','点赞量','发帖人发帖数','发帖人评论数','发帖人关注数','发帖人粉丝数','发帖人影响力','发帖人吧龄','发帖人总访问量','发帖人今日访问量']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list,qh\n",
      "list,rb\n",
      "list,wr\n",
      "list,cu\n",
      "list,al\n",
      "list,ru\n",
      "list,fu\n",
      "list,zn\n",
      "list,au\n",
      "list,pb\n",
      "list,baiyin\n",
      "list,m\n",
      "list,a\n",
      "list,c\n",
      "list,fshfesn\n",
      "list,fshfeni\n",
      "list,y\n",
      "list,l\n",
      "list,p\n",
      "list,v\n",
      "list,j\n",
      "list,wt\n",
      "list,ws\n",
      "list,cf\n",
      "list,sr\n",
      "list,ta\n",
      "list,ro\n",
      "list,er\n",
      "list,me\n",
      "list,tc\n",
      "list,bu\n",
      "list,i\n",
      "list,jd\n",
      "list,jrx\n",
      "list,bb\n",
      "list,fb\n",
      "list,pp\n",
      "list,hc\n",
      "list,lr\n",
      "list,sf\n",
      "list,sm\n",
      "list,cs\n",
      "list,gzqh\n",
      "list,if01\n",
      "list,if02\n",
      "list,if03\n",
      "list,if04\n",
      "list,if05\n",
      "list,if06\n",
      "list,if07\n",
      "list,if08\n",
      "list,if09\n",
      "list,if10\n",
      "list,if11\n",
      "list,if12\n",
      "list,gzqh2\n",
      "13314\n"
     ]
    }
   ],
   "source": [
    "baseurl = \"http://guba.eastmoney.com/\"\n",
    "for code in futures_code:\n",
    "    print(code)\n",
    "    url = baseurl+code\n",
    "    for page in range(1,101): #收集某个期货吧的前100页上所有帖子的链接\n",
    "        soup = decode(url+'_'+str(page)+'.html')\n",
    "        for item in soup.find_all('div',class_=\"articleh normal_post\"):\n",
    "            links.append(item.find('a').attrs['href'].replace('/',''))\n",
    "\n",
    "links_url = []\n",
    "for i in links:\n",
    "    links_url.append(\"http://guba.eastmoney.com/\"+i) \n",
    "\n",
    "f = open('links_url.txt','w')\n",
    "f.write(str(links_url))\n",
    "\n",
    "print(len(links_url)) #待爬链接数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links_url:\n",
    "    html = decode(url)\n",
    "    parse(html)\n",
    "\n",
    "result = pd.DataFrame(columns).T\n",
    "result.columns = col_name\n",
    "result.to_excel('data_before_clear.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4721 entries, 0 to 4720\n",
      "Data columns (total 19 columns):\n",
      "查询时间        4721 non-null object\n",
      "发帖吧         4721 non-null object\n",
      "发帖id        4721 non-null object\n",
      "发帖人         4721 non-null object\n",
      "发帖内容        4721 non-null object\n",
      "发帖时间        4721 non-null object\n",
      "是否为主贴       4721 non-null int64\n",
      "是否有图片       4721 non-null float64\n",
      "阅读量         4721 non-null object\n",
      "评论量         4721 non-null object\n",
      "点赞量         4721 non-null float64\n",
      "发帖人发帖数      4721 non-null float64\n",
      "发帖人评论数      4721 non-null float64\n",
      "发帖人关注数      4721 non-null float64\n",
      "发帖人粉丝数      4721 non-null float64\n",
      "发帖人影响力      4721 non-null float64\n",
      "发帖人吧龄       4721 non-null float64\n",
      "发帖人总访问量     4721 non-null float64\n",
      "发帖人今日访问量    4721 non-null float64\n",
      "dtypes: float64(10), int64(1), object(8)\n",
      "memory usage: 700.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>查询时间</th>\n",
       "      <th>发帖吧</th>\n",
       "      <th>发帖id</th>\n",
       "      <th>发帖人</th>\n",
       "      <th>发帖内容</th>\n",
       "      <th>发帖时间</th>\n",
       "      <th>是否为主贴</th>\n",
       "      <th>是否有图片</th>\n",
       "      <th>阅读量</th>\n",
       "      <th>评论量</th>\n",
       "      <th>点赞量</th>\n",
       "      <th>发帖人发帖数</th>\n",
       "      <th>发帖人评论数</th>\n",
       "      <th>发帖人关注数</th>\n",
       "      <th>发帖人粉丝数</th>\n",
       "      <th>发帖人影响力</th>\n",
       "      <th>发帖人吧龄</th>\n",
       "      <th>发帖人总访问量</th>\n",
       "      <th>发帖人今日访问量</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-12-08 09:24:38</td>\n",
       "      <td>棕榈油2006</td>\n",
       "      <td>2198024737861310.0</td>\n",
       "      <td>西门散户</td>\n",
       "      <td>这波棕榈怎么玩才能稳定赚钱？首先要明白怎么玩期货赚钱!我的思路一直是轻仓长线。做这波棕榈怎么...</td>\n",
       "      <td>2019-12-06 00:32:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12502</td>\n",
       "      <td>158</td>\n",
       "      <td>87.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>19891.0</td>\n",
       "      <td>578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-08 09:24:38</td>\n",
       "      <td>棕榈油2006</td>\n",
       "      <td>2198024737861310.0</td>\n",
       "      <td>西门散户</td>\n",
       "      <td>手机打字有错误理解</td>\n",
       "      <td>2019-12-06 00:36:25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>19891.0</td>\n",
       "      <td>578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-08 09:24:38</td>\n",
       "      <td>棕榈油2006</td>\n",
       "      <td>2606054690823332.0</td>\n",
       "      <td>只买垃圾168</td>\n",
       "      <td>高手、顶一个、镍吧里看到过你发言</td>\n",
       "      <td>2019-12-06 00:41:49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-12-08 09:24:38</td>\n",
       "      <td>棕榈油2006</td>\n",
       "      <td>2198024737861310.0</td>\n",
       "      <td>西门散户</td>\n",
       "      <td>我认为做任何品种都是一样的的，只要有自己思考框架，交易框架，慢慢积少成多。</td>\n",
       "      <td>2019-12-06 00:43:24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>19891.0</td>\n",
       "      <td>578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-12-08 09:24:38</td>\n",
       "      <td>棕榈油2006</td>\n",
       "      <td>2198024737861310.0</td>\n",
       "      <td>西门散户</td>\n",
       "      <td>之前我做了一波镍的完全记录在沪镍吧，每周都有热帖，其实持仓过程比较煎熬的。还好沪镍一直走单边。</td>\n",
       "      <td>2019-12-06 00:45:16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>19891.0</td>\n",
       "      <td>578.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  查询时间      发帖吧                发帖id      发帖人  \\\n",
       "0  2019-12-08 09:24:38  棕榈油2006  2198024737861310.0     西门散户   \n",
       "1  2019-12-08 09:24:38  棕榈油2006  2198024737861310.0     西门散户   \n",
       "2  2019-12-08 09:24:38  棕榈油2006  2606054690823332.0  只买垃圾168   \n",
       "3  2019-12-08 09:24:38  棕榈油2006  2198024737861310.0     西门散户   \n",
       "4  2019-12-08 09:24:38  棕榈油2006  2198024737861310.0     西门散户   \n",
       "\n",
       "                                                发帖内容                 发帖时间  \\\n",
       "0  这波棕榈怎么玩才能稳定赚钱？首先要明白怎么玩期货赚钱!我的思路一直是轻仓长线。做这波棕榈怎么...  2019-12-06 00:32:38   \n",
       "1                                          手机打字有错误理解  2019-12-06 00:36:25   \n",
       "2                                   高手、顶一个、镍吧里看到过你发言  2019-12-06 00:41:49   \n",
       "3              我认为做任何品种都是一样的的，只要有自己思考框架，交易框架，慢慢积少成多。  2019-12-06 00:43:24   \n",
       "4    之前我做了一波镍的完全记录在沪镍吧，每周都有热帖，其实持仓过程比较煎熬的。还好沪镍一直走单边。  2019-12-06 00:45:16   \n",
       "\n",
       "   是否为主贴  是否有图片    阅读量  评论量   点赞量  发帖人发帖数  发帖人评论数  发帖人关注数  发帖人粉丝数  发帖人影响力  \\\n",
       "0      1    0.0  12502  158  87.0   599.0  1342.0     7.0   762.0     6.0   \n",
       "1      1    0.0    NAN  NAN   0.0   599.0  1342.0     7.0   762.0     6.0   \n",
       "2      0    0.0    NAN  NAN   6.0   833.0   545.0     5.0    10.0     5.0   \n",
       "3      1    0.0    NAN  NAN   1.0   599.0  1342.0     7.0   762.0     6.0   \n",
       "4      1    0.0    NAN  NAN   1.0   599.0  1342.0     7.0   762.0     6.0   \n",
       "\n",
       "   发帖人吧龄  发帖人总访问量  发帖人今日访问量  \n",
       "0    3.3  19891.0     578.0  \n",
       "1    3.3  19891.0     578.0  \n",
       "2    3.4   4083.0      22.0  \n",
       "3    3.3  19891.0     578.0  \n",
       "4    3.3  19891.0     578.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##数据清洗\n",
    "df = pd.read_excel('p1.xlsx')\n",
    "#df.drop(axis = 1,labels='Unnamed: 0',inplace=True)\n",
    "#删除特定发帖人\n",
    "droped_rows = [i for i,x in enumerate(df['发帖人']) if df['发帖人'][i] in ['财经评论','东方财富网','期货小秘书']]\n",
    "df.drop(droped_rows,axis=0)\n",
    "#清洗评论内容\n",
    "df['发帖内容'].fillna('空值',inplace=True)\n",
    "null_list = df[(df['发帖内容']=='空值')].index.tolist()\n",
    "df = df.drop(null_list)\n",
    "reviews_cleared = []\n",
    "for text in df['发帖内容']:\n",
    "    reviews_cleared.append(text.replace(\" \",'').replace(\"\\n\",'').replace(\"\\r\",''))\n",
    "df['发帖内容'] = reviews_cleared\n",
    "#数据格式变更\n",
    "df['发帖吧'] = df['发帖吧'].apply(lambda x: str(x).replace('\"',\"\"))\n",
    "df['发帖id'] = df['发帖id'].apply(str)\n",
    "df['是否为主贴'] = df['是否为主贴'].apply(lambda x: 0 if x==False else 1)\n",
    "df['发帖人吧龄'] = df['发帖人吧龄'].apply(lambda x: x.replace(\"年\",\"\"))\n",
    "df['发帖人吧龄'] = df['发帖人吧龄'].apply(lambda x: str(float(x.replace(\"个月\",\"\"))/12) if \"个月\" in x else x)\n",
    "df['发帖人吧龄'] = df['发帖人吧龄'].apply(lambda x: float(x.replace(\"天\",\"\"))/365 if \"天\" in x else float(x))\n",
    "df = df.fillna('NAN').reset_index().drop(columns='index')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# n日活跃度feature构建\n",
    "time_delta = pd.to_datetime(df['查询时间'])-pd.to_datetime(df['发帖时间'])\n",
    "time_delta = round(time_delta.apply(lambda x: float(re.findall('\\d+', str(x))[0])+float(re.findall('\\d+', str(x))[1])/24),4)\n",
    "df['Time_delta'] = time_delta\n",
    "\n",
    "n_num_reviews = np.zeros(len(df))\n",
    "\n",
    "def n_day_activity(n):\n",
    "    df_copy = df[df['Time_delta']<=n]\n",
    "    _id = list(df_copy.groupby('发帖id', as_index=False).count()['发帖id'])\n",
    "    num_reviews = list(df_copy.groupby('发帖id', as_index=False).count()['发帖人'])\n",
    "    id_dict = dict(zip(_id,num_reviews))\n",
    "    for i in range(len(df)):\n",
    "        if df['发帖id'][i] not in id_dict: n_num_reviews[i] = 0\n",
    "        else: n_num_reviews[i] = id_dict[df['发帖id'][i]]\n",
    "    df['近n日发帖数'] = n_num_reviews\n",
    "    return df\n",
    "\n",
    "n = input()\n",
    "n_day_activity(int(n)).to_excel('data_processed.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
